{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of sarcasm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuSBImBrDNwb",
        "colab_type": "code",
        "outputId": "9dda9a25-66c6-43a8-8683-cdd2662ca604",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.preprocessing.text import *\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifWq_tptDwQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df=pd.read_json('/content/drive/My Drive/Sarcasm/sarcasm2.json',lines=True)\n",
        "df=pd.read_json('Sarcasm_Headlines_Dataset.json',lines=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VUP7odIFgph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcXRMLLcEGb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y=df.is_sarcastic"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zv-tbLJgFojU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "X=df.headline\n",
        "x=df.headline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsVkwI8aTsMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "max_words=20000\n",
        "token=Tokenizer()#num_words=max_words)\n",
        "token.fit_on_texts(X)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oUUSdFABkuC",
        "colab_type": "code",
        "outputId": "797aa435-171e-46bb-ad25-61ddb2b84985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "token.word_index"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'to': 1,\n",
              " 'of': 2,\n",
              " 'the': 3,\n",
              " 'in': 4,\n",
              " 'for': 5,\n",
              " 'a': 6,\n",
              " 'on': 7,\n",
              " 'and': 8,\n",
              " 'with': 9,\n",
              " 'is': 10,\n",
              " 'new': 11,\n",
              " 'trump': 12,\n",
              " 'man': 13,\n",
              " 'from': 14,\n",
              " 'at': 15,\n",
              " 'about': 16,\n",
              " 'you': 17,\n",
              " 'this': 18,\n",
              " 'by': 19,\n",
              " 'after': 20,\n",
              " 'up': 21,\n",
              " 'out': 22,\n",
              " 'be': 23,\n",
              " 'how': 24,\n",
              " 'as': 25,\n",
              " 'it': 26,\n",
              " 'that': 27,\n",
              " 'not': 28,\n",
              " 'are': 29,\n",
              " 'your': 30,\n",
              " 'his': 31,\n",
              " 'what': 32,\n",
              " 'he': 33,\n",
              " 'all': 34,\n",
              " 'just': 35,\n",
              " 'who': 36,\n",
              " 'has': 37,\n",
              " 'will': 38,\n",
              " 'more': 39,\n",
              " 'one': 40,\n",
              " 'into': 41,\n",
              " 'report': 42,\n",
              " 'year': 43,\n",
              " 'why': 44,\n",
              " 'have': 45,\n",
              " 'area': 46,\n",
              " 'over': 47,\n",
              " 'donald': 48,\n",
              " 'u': 49,\n",
              " 'day': 50,\n",
              " 'says': 51,\n",
              " 's': 52,\n",
              " 'can': 53,\n",
              " 'first': 54,\n",
              " 'woman': 55,\n",
              " 'time': 56,\n",
              " 'like': 57,\n",
              " 'her': 58,\n",
              " \"trump's\": 59,\n",
              " 'old': 60,\n",
              " 'no': 61,\n",
              " 'get': 62,\n",
              " 'off': 63,\n",
              " 'an': 64,\n",
              " 'life': 65,\n",
              " 'people': 66,\n",
              " 'obama': 67,\n",
              " 'now': 68,\n",
              " 'house': 69,\n",
              " 'still': 70,\n",
              " \"'\": 71,\n",
              " 'women': 72,\n",
              " 'make': 73,\n",
              " 'was': 74,\n",
              " 'than': 75,\n",
              " 'white': 76,\n",
              " 'back': 77,\n",
              " 'my': 78,\n",
              " 'i': 79,\n",
              " 'clinton': 80,\n",
              " 'down': 81,\n",
              " 'if': 82,\n",
              " '5': 83,\n",
              " 'when': 84,\n",
              " 'world': 85,\n",
              " 'could': 86,\n",
              " 'we': 87,\n",
              " 'their': 88,\n",
              " 'before': 89,\n",
              " 'americans': 90,\n",
              " 'way': 91,\n",
              " 'do': 92,\n",
              " 'family': 93,\n",
              " 'most': 94,\n",
              " 'gop': 95,\n",
              " 'they': 96,\n",
              " 'study': 97,\n",
              " 'school': 98,\n",
              " \"it's\": 99,\n",
              " 'black': 100,\n",
              " 'best': 101,\n",
              " 'years': 102,\n",
              " 'bill': 103,\n",
              " 'should': 104,\n",
              " '3': 105,\n",
              " 'him': 106,\n",
              " 'would': 107,\n",
              " 'so': 108,\n",
              " 'police': 109,\n",
              " 'only': 110,\n",
              " 'watch': 111,\n",
              " 'american': 112,\n",
              " 'really': 113,\n",
              " 'being': 114,\n",
              " 'but': 115,\n",
              " 'last': 116,\n",
              " 'know': 117,\n",
              " '10': 118,\n",
              " \"can't\": 119,\n",
              " 'death': 120,\n",
              " 'home': 121,\n",
              " 'during': 122,\n",
              " 'video': 123,\n",
              " 'finds': 124,\n",
              " 'state': 125,\n",
              " 'or': 126,\n",
              " 'president': 127,\n",
              " 'health': 128,\n",
              " 'going': 129,\n",
              " 'say': 130,\n",
              " 'show': 131,\n",
              " 'nation': 132,\n",
              " 'good': 133,\n",
              " 'things': 134,\n",
              " 'hillary': 135,\n",
              " \"'the\": 136,\n",
              " 'may': 137,\n",
              " '2': 138,\n",
              " 'against': 139,\n",
              " 'campaign': 140,\n",
              " 'every': 141,\n",
              " 'she': 142,\n",
              " 'love': 143,\n",
              " 'mom': 144,\n",
              " 'need': 145,\n",
              " 'big': 146,\n",
              " 'right': 147,\n",
              " 'party': 148,\n",
              " 'gets': 149,\n",
              " '000': 150,\n",
              " 'too': 151,\n",
              " 'getting': 152,\n",
              " 'these': 153,\n",
              " 'kids': 154,\n",
              " 'some': 155,\n",
              " 'parents': 156,\n",
              " 'work': 157,\n",
              " 'court': 158,\n",
              " 'little': 159,\n",
              " 'change': 160,\n",
              " 'take': 161,\n",
              " 'high': 162,\n",
              " 'makes': 163,\n",
              " 'self': 164,\n",
              " 'our': 165,\n",
              " 'calls': 166,\n",
              " 'john': 167,\n",
              " 'other': 168,\n",
              " 'news': 169,\n",
              " 'through': 170,\n",
              " \"doesn't\": 171,\n",
              " 'while': 172,\n",
              " \"here's\": 173,\n",
              " 'never': 174,\n",
              " 'child': 175,\n",
              " 'gay': 176,\n",
              " 'dead': 177,\n",
              " 'look': 178,\n",
              " 'election': 179,\n",
              " 'want': 180,\n",
              " 'own': 181,\n",
              " '4': 182,\n",
              " \"don't\": 183,\n",
              " 'see': 184,\n",
              " 'takes': 185,\n",
              " 'america': 186,\n",
              " '7': 187,\n",
              " 'local': 188,\n",
              " 'real': 189,\n",
              " 'where': 190,\n",
              " 'next': 191,\n",
              " 'stop': 192,\n",
              " 'even': 193,\n",
              " 'its': 194,\n",
              " \"he's\": 195,\n",
              " 'war': 196,\n",
              " 'college': 197,\n",
              " 'go': 198,\n",
              " '6': 199,\n",
              " \"nation's\": 200,\n",
              " 'sex': 201,\n",
              " 'bush': 202,\n",
              " 'made': 203,\n",
              " 'plan': 204,\n",
              " 'office': 205,\n",
              " 'again': 206,\n",
              " 'guy': 207,\n",
              " 'two': 208,\n",
              " 'dad': 209,\n",
              " 'another': 210,\n",
              " 'around': 211,\n",
              " 'dog': 212,\n",
              " 'got': 213,\n",
              " '1': 214,\n",
              " 'million': 215,\n",
              " 'ever': 216,\n",
              " 'week': 217,\n",
              " 'baby': 218,\n",
              " 'debate': 219,\n",
              " 'thing': 220,\n",
              " 'them': 221,\n",
              " 'gun': 222,\n",
              " 'wants': 223,\n",
              " 'care': 224,\n",
              " 'us': 225,\n",
              " 'help': 226,\n",
              " 'much': 227,\n",
              " 'long': 228,\n",
              " 'night': 229,\n",
              " 'congress': 230,\n",
              " 'job': 231,\n",
              " 'finally': 232,\n",
              " 'north': 233,\n",
              " 'been': 234,\n",
              " 'under': 235,\n",
              " \"man's\": 236,\n",
              " 'actually': 237,\n",
              " 'star': 238,\n",
              " 'national': 239,\n",
              " 'live': 240,\n",
              " 'climate': 241,\n",
              " 'season': 242,\n",
              " 'money': 243,\n",
              " 'couple': 244,\n",
              " \"won't\": 245,\n",
              " '8': 246,\n",
              " '9': 247,\n",
              " 'top': 248,\n",
              " 'god': 249,\n",
              " 'anti': 250,\n",
              " 'media': 251,\n",
              " 'food': 252,\n",
              " 'ways': 253,\n",
              " '20': 254,\n",
              " 'shows': 255,\n",
              " 'sexual': 256,\n",
              " 'better': 257,\n",
              " 'give': 258,\n",
              " 'shooting': 259,\n",
              " 'had': 260,\n",
              " 'teen': 261,\n",
              " 'face': 262,\n",
              " 'making': 263,\n",
              " 'game': 264,\n",
              " 'paul': 265,\n",
              " 'reveals': 266,\n",
              " 'me': 267,\n",
              " 'trying': 268,\n",
              " 'senate': 269,\n",
              " 'supreme': 270,\n",
              " 'announces': 271,\n",
              " 'there': 272,\n",
              " 'away': 273,\n",
              " 'men': 274,\n",
              " 'history': 275,\n",
              " 'business': 276,\n",
              " 'bad': 277,\n",
              " 'without': 278,\n",
              " 'students': 279,\n",
              " 'everyone': 280,\n",
              " 'attack': 281,\n",
              " 'end': 282,\n",
              " 'story': 283,\n",
              " 'fight': 284,\n",
              " 'facebook': 285,\n",
              " 'son': 286,\n",
              " 'free': 287,\n",
              " 'children': 288,\n",
              " 'enough': 289,\n",
              " 'tv': 290,\n",
              " 'law': 291,\n",
              " 'movie': 292,\n",
              " 'city': 293,\n",
              " 'any': 294,\n",
              " 'introduces': 295,\n",
              " 'pope': 296,\n",
              " 'deal': 297,\n",
              " 'government': 298,\n",
              " 'body': 299,\n",
              " 'part': 300,\n",
              " 'york': 301,\n",
              " '11': 302,\n",
              " 'tell': 303,\n",
              " 'great': 304,\n",
              " 'film': 305,\n",
              " 'does': 306,\n",
              " 'former': 307,\n",
              " 'single': 308,\n",
              " 'entire': 309,\n",
              " 'friends': 310,\n",
              " 'fire': 311,\n",
              " 'call': 312,\n",
              " 'found': 313,\n",
              " 'friend': 314,\n",
              " 'book': 315,\n",
              " 'wedding': 316,\n",
              " 'think': 317,\n",
              " 'come': 318,\n",
              " 'republican': 319,\n",
              " 'must': 320,\n",
              " 'girl': 321,\n",
              " 'find': 322,\n",
              " 'second': 323,\n",
              " 'middle': 324,\n",
              " 'morning': 325,\n",
              " 'support': 326,\n",
              " 'same': 327,\n",
              " 'speech': 328,\n",
              " 'public': 329,\n",
              " 'photos': 330,\n",
              " 'use': 331,\n",
              " 'talk': 332,\n",
              " 'line': 333,\n",
              " 'car': 334,\n",
              " 'sanders': 335,\n",
              " 'name': 336,\n",
              " 'keep': 337,\n",
              " 'thinks': 338,\n",
              " 'run': 339,\n",
              " 'already': 340,\n",
              " 'looking': 341,\n",
              " 'presidential': 342,\n",
              " 'coming': 343,\n",
              " 'james': 344,\n",
              " 'republicans': 345,\n",
              " 'email': 346,\n",
              " \"didn't\": 347,\n",
              " 'tax': 348,\n",
              " 'pretty': 349,\n",
              " 'case': 350,\n",
              " 'company': 351,\n",
              " 'behind': 352,\n",
              " 'rights': 353,\n",
              " 'power': 354,\n",
              " 'open': 355,\n",
              " 'future': 356,\n",
              " 'marriage': 357,\n",
              " 'between': 358,\n",
              " 'releases': 359,\n",
              " 'violence': 360,\n",
              " 'christmas': 361,\n",
              " 'security': 362,\n",
              " '2016': 363,\n",
              " \"world's\": 364,\n",
              " 'used': 365,\n",
              " 'human': 366,\n",
              " 'killed': 367,\n",
              " 'voters': 368,\n",
              " 'once': 369,\n",
              " 'control': 370,\n",
              " 'goes': 371,\n",
              " 'group': 372,\n",
              " 'vote': 373,\n",
              " 'win': 374,\n",
              " 'might': 375,\n",
              " 'democrats': 376,\n",
              " 'student': 377,\n",
              " 'full': 378,\n",
              " 'something': 379,\n",
              " 'doing': 380,\n",
              " 'secret': 381,\n",
              " 'asks': 382,\n",
              " 'fans': 383,\n",
              " '12': 384,\n",
              " 'having': 385,\n",
              " 'team': 386,\n",
              " 'bernie': 387,\n",
              " 'department': 388,\n",
              " 'twitter': 389,\n",
              " 'room': 390,\n",
              " 'ban': 391,\n",
              " 'ad': 392,\n",
              " 'because': 393,\n",
              " 'poll': 394,\n",
              " 'teacher': 395,\n",
              " 'female': 396,\n",
              " 'post': 397,\n",
              " 'each': 398,\n",
              " 'wife': 399,\n",
              " 'inside': 400,\n",
              " 'ryan': 401,\n",
              " 'sure': 402,\n",
              " 'race': 403,\n",
              " 'claims': 404,\n",
              " 'music': 405,\n",
              " 'three': 406,\n",
              " 'meet': 407,\n",
              " 'record': 408,\n",
              " 'art': 409,\n",
              " 'forced': 410,\n",
              " 'boy': 411,\n",
              " '15': 412,\n",
              " 'missing': 413,\n",
              " 'many': 414,\n",
              " 'political': 415,\n",
              " 'unveils': 416,\n",
              " 'perfect': 417,\n",
              " 'head': 418,\n",
              " 'super': 419,\n",
              " 'very': 420,\n",
              " 'photo': 421,\n",
              " 'judge': 422,\n",
              " 'running': 423,\n",
              " 'reports': 424,\n",
              " 'red': 425,\n",
              " 'father': 426,\n",
              " 'save': 427,\n",
              " 'class': 428,\n",
              " 'scientists': 429,\n",
              " 'month': 430,\n",
              " 'plans': 431,\n",
              " 'days': 432,\n",
              " 'country': 433,\n",
              " 'person': 434,\n",
              " 'living': 435,\n",
              " 'tells': 436,\n",
              " 'social': 437,\n",
              " 'minutes': 438,\n",
              " 'put': 439,\n",
              " 'summer': 440,\n",
              " 'everything': 441,\n",
              " 'dies': 442,\n",
              " 'california': 443,\n",
              " 'always': 444,\n",
              " 'until': 445,\n",
              " 'obamacare': 446,\n",
              " 'states': 447,\n",
              " 'here': 448,\n",
              " 'pay': 449,\n",
              " 'ready': 450,\n",
              " 'texas': 451,\n",
              " 'were': 452,\n",
              " 'michael': 453,\n",
              " 'looks': 454,\n",
              " 'employee': 455,\n",
              " 'talks': 456,\n",
              " 'candidate': 457,\n",
              " 'needs': 458,\n",
              " 'did': 459,\n",
              " 'eating': 460,\n",
              " 'working': 461,\n",
              " 'water': 462,\n",
              " 'list': 463,\n",
              " 'justice': 464,\n",
              " 'secretary': 465,\n",
              " 'shot': 466,\n",
              " 'hot': 467,\n",
              " 'warns': 468,\n",
              " 'times': 469,\n",
              " 'comes': 470,\n",
              " 'past': 471,\n",
              " 'admits': 472,\n",
              " 'set': 473,\n",
              " 'start': 474,\n",
              " 'taking': 475,\n",
              " 'wall': 476,\n",
              " 'heart': 477,\n",
              " 'ceo': 478,\n",
              " 'ex': 479,\n",
              " 'thought': 480,\n",
              " \"'i\": 481,\n",
              " 'lives': 482,\n",
              " 'age': 483,\n",
              " 'left': 484,\n",
              " 'mike': 485,\n",
              " 'mother': 486,\n",
              " 'town': 487,\n",
              " 'gives': 488,\n",
              " '30': 489,\n",
              " 'let': 490,\n",
              " 'cruz': 491,\n",
              " \"women's\": 492,\n",
              " 'kim': 493,\n",
              " 'russia': 494,\n",
              " 'idea': 495,\n",
              " 'drug': 496,\n",
              " 'chief': 497,\n",
              " 'phone': 498,\n",
              " \"you're\": 499,\n",
              " 'cancer': 500,\n",
              " 'george': 501,\n",
              " 'crisis': 502,\n",
              " 'service': 503,\n",
              " 'biden': 504,\n",
              " 'wins': 505,\n",
              " 'hours': 506,\n",
              " \"i'm\": 507,\n",
              " 'letter': 508,\n",
              " 'wrong': 509,\n",
              " 'tips': 510,\n",
              " 'meeting': 511,\n",
              " 'south': 512,\n",
              " 'korea': 513,\n",
              " 'lost': 514,\n",
              " 'breaking': 515,\n",
              " 'daughter': 516,\n",
              " 'air': 517,\n",
              " '50': 518,\n",
              " 'probably': 519,\n",
              " 'young': 520,\n",
              " 'fbi': 521,\n",
              " 'street': 522,\n",
              " 'dream': 523,\n",
              " 'percent': 524,\n",
              " 'yet': 525,\n",
              " 'education': 526,\n",
              " 'isis': 527,\n",
              " 'romney': 528,\n",
              " 'word': 529,\n",
              " 'thousands': 530,\n",
              " 'restaurant': 531,\n",
              " 'small': 532,\n",
              " 'nuclear': 533,\n",
              " 'fucking': 534,\n",
              " 'kill': 535,\n",
              " 'today': 536,\n",
              " 'believe': 537,\n",
              " 'king': 538,\n",
              " 'tweets': 539,\n",
              " 'together': 540,\n",
              " 'half': 541,\n",
              " 'someone': 542,\n",
              " 'ted': 543,\n",
              " 'hard': 544,\n",
              " 'questions': 545,\n",
              " 'military': 546,\n",
              " 'march': 547,\n",
              " \"she's\": 548,\n",
              " 'few': 549,\n",
              " 'administration': 550,\n",
              " 'owner': 551,\n",
              " 'feel': 552,\n",
              " 'cat': 553,\n",
              " 'leaves': 554,\n",
              " 'fan': 555,\n",
              " 'internet': 556,\n",
              " 'officials': 557,\n",
              " 'third': 558,\n",
              " 'talking': 559,\n",
              " 'nothing': 560,\n",
              " 'director': 561,\n",
              " 'federal': 562,\n",
              " 'sleep': 563,\n",
              " 'chris': 564,\n",
              " 'rock': 565,\n",
              " 'place': 566,\n",
              " \"what's\": 567,\n",
              " 'washington': 568,\n",
              " 'guide': 569,\n",
              " 'online': 570,\n",
              " 'attacks': 571,\n",
              " 'muslim': 572,\n",
              " 'earth': 573,\n",
              " 'giving': 574,\n",
              " 'move': 575,\n",
              " 'lot': 576,\n",
              " 'florida': 577,\n",
              " 'ask': 578,\n",
              " 'iran': 579,\n",
              " 'latest': 580,\n",
              " 'series': 581,\n",
              " 'holiday': 582,\n",
              " 'congressman': 583,\n",
              " 'community': 584,\n",
              " 'abortion': 585,\n",
              " 'well': 586,\n",
              " 'order': 587,\n",
              " 'buy': 588,\n",
              " 'personal': 589,\n",
              " 'less': 590,\n",
              " 'months': 591,\n",
              " 'majority': 592,\n",
              " 'birthday': 593,\n",
              " 'hour': 594,\n",
              " 't': 595,\n",
              " 'prison': 596,\n",
              " '2015': 597,\n",
              " 'democratic': 598,\n",
              " 'outside': 599,\n",
              " 'problem': 600,\n",
              " 'leave': 601,\n",
              " 'assault': 602,\n",
              " 'those': 603,\n",
              " 'shit': 604,\n",
              " 'travel': 605,\n",
              " 'hollywood': 606,\n",
              " 'wearing': 607,\n",
              " 'beautiful': 608,\n",
              " 'girlfriend': 609,\n",
              " \"isn't\": 610,\n",
              " 'ice': 611,\n",
              " 'reason': 612,\n",
              " 'bar': 613,\n",
              " 'francis': 614,\n",
              " 'told': 615,\n",
              " 'different': 616,\n",
              " 'favorite': 617,\n",
              " 'issues': 618,\n",
              " 'cover': 619,\n",
              " 'rules': 620,\n",
              " 'rise': 621,\n",
              " 'happy': 622,\n",
              " 'fox': 623,\n",
              " 'fun': 624,\n",
              " 'special': 625,\n",
              " 'mark': 626,\n",
              " 'system': 627,\n",
              " 'read': 628,\n",
              " 'watching': 629,\n",
              " 'reasons': 630,\n",
              " 'girls': 631,\n",
              " 'straight': 632,\n",
              " 'play': 633,\n",
              " \"america's\": 634,\n",
              " 'al': 635,\n",
              " 'celebrates': 636,\n",
              " \"obama's\": 637,\n",
              " 'minute': 638,\n",
              " 'thinking': 639,\n",
              " 'hate': 640,\n",
              " 'excited': 641,\n",
              " 'relationship': 642,\n",
              " 'trip': 643,\n",
              " 'hit': 644,\n",
              " 'response': 645,\n",
              " 'huffpost': 646,\n",
              " 'knows': 647,\n",
              " 'russian': 648,\n",
              " 'immigration': 649,\n",
              " 'protest': 650,\n",
              " 'scott': 651,\n",
              " 'following': 652,\n",
              " '100': 653,\n",
              " 'using': 654,\n",
              " 'offers': 655,\n",
              " 'front': 656,\n",
              " 'message': 657,\n",
              " 'trailer': 658,\n",
              " 'stars': 659,\n",
              " 'leaders': 660,\n",
              " 'visit': 661,\n",
              " 'stephen': 662,\n",
              " 'hair': 663,\n",
              " 'huge': 664,\n",
              " 'box': 665,\n",
              " 'gift': 666,\n",
              " 'david': 667,\n",
              " 'union': 668,\n",
              " 'kind': 669,\n",
              " 'kid': 670,\n",
              " 'since': 671,\n",
              " 'moment': 672,\n",
              " 'china': 673,\n",
              " 'chinese': 674,\n",
              " 'birth': 675,\n",
              " 'non': 676,\n",
              " 'cop': 677,\n",
              " 'store': 678,\n",
              " 'lessons': 679,\n",
              " 'late': 680,\n",
              " 'hope': 681,\n",
              " 'accused': 682,\n",
              " 'taylor': 683,\n",
              " 'date': 684,\n",
              " 'career': 685,\n",
              " 'interview': 686,\n",
              " 'himself': 687,\n",
              " 'politics': 688,\n",
              " 'weekend': 689,\n",
              " 'called': 690,\n",
              " 'early': 691,\n",
              " 'victims': 692,\n",
              " 'least': 693,\n",
              " 'bring': 694,\n",
              " 'senator': 695,\n",
              " 'whole': 696,\n",
              " 'tom': 697,\n",
              " 'conversation': 698,\n",
              " 'adorable': 699,\n",
              " 'waiting': 700,\n",
              " 'jimmy': 701,\n",
              " 'break': 702,\n",
              " 'sports': 703,\n",
              " 'syria': 704,\n",
              " 'powerful': 705,\n",
              " 'drunk': 706,\n",
              " 'c': 707,\n",
              " 'point': 708,\n",
              " 'united': 709,\n",
              " 'leader': 710,\n",
              " 'anything': 711,\n",
              " 'become': 712,\n",
              " 'investigation': 713,\n",
              " 'opens': 714,\n",
              " 'learned': 715,\n",
              " 'words': 716,\n",
              " 'millions': 717,\n",
              " 'k': 718,\n",
              " 'die': 719,\n",
              " 'fashion': 720,\n",
              " 'cops': 721,\n",
              " \"they're\": 722,\n",
              " 'reality': 723,\n",
              " 'billion': 724,\n",
              " 'fall': 725,\n",
              " 'key': 726,\n",
              " 'true': 727,\n",
              " 'host': 728,\n",
              " 'returns': 729,\n",
              " 'joe': 730,\n",
              " 'totally': 731,\n",
              " 'syrian': 732,\n",
              " 'killing': 733,\n",
              " 'massive': 734,\n",
              " '40': 735,\n",
              " 'almost': 736,\n",
              " 'turn': 737,\n",
              " 'breaks': 738,\n",
              " 'driving': 739,\n",
              " 'mass': 740,\n",
              " 'global': 741,\n",
              " 'dating': 742,\n",
              " 'far': 743,\n",
              " 'policy': 744,\n",
              " 'schools': 745,\n",
              " 'stand': 746,\n",
              " 'trans': 747,\n",
              " 'dinner': 748,\n",
              " 'oil': 749,\n",
              " 'apple': 750,\n",
              " 'un': 751,\n",
              " 'awards': 752,\n",
              " 'queer': 753,\n",
              " 'worried': 754,\n",
              " 'kills': 755,\n",
              " 'iraq': 756,\n",
              " 'low': 757,\n",
              " 'song': 758,\n",
              " 'dance': 759,\n",
              " 'turns': 760,\n",
              " 'puts': 761,\n",
              " 'spends': 762,\n",
              " 'stage': 763,\n",
              " 'sign': 764,\n",
              " 'candidates': 765,\n",
              " 'j': 766,\n",
              " 'vows': 767,\n",
              " 'risk': 768,\n",
              " 'bus': 769,\n",
              " 'names': 770,\n",
              " 'final': 771,\n",
              " 'planned': 772,\n",
              " 'feels': 773,\n",
              " 'anniversary': 774,\n",
              " 'lgbt': 775,\n",
              " 'signs': 776,\n",
              " 'jr': 777,\n",
              " 'murder': 778,\n",
              " 'seen': 779,\n",
              " 'prince': 780,\n",
              " 'reportedly': 781,\n",
              " 'hits': 782,\n",
              " 'light': 783,\n",
              " 'sick': 784,\n",
              " 'adds': 785,\n",
              " 'crash': 786,\n",
              " 'd': 787,\n",
              " 'worst': 788,\n",
              " 'surprise': 789,\n",
              " 'hands': 790,\n",
              " 'near': 791,\n",
              " 'transgender': 792,\n",
              " 'weird': 793,\n",
              " 'nfl': 794,\n",
              " 'return': 795,\n",
              " 'moving': 796,\n",
              " \"there's\": 797,\n",
              " 'pence': 798,\n",
              " 'mind': 799,\n",
              " 'center': 800,\n",
              " 'decision': 801,\n",
              " 'longer': 802,\n",
              " 'workers': 803,\n",
              " 'advice': 804,\n",
              " 'worth': 805,\n",
              " 'eat': 806,\n",
              " 'struggling': 807,\n",
              " 'discover': 808,\n",
              " 'oscar': 809,\n",
              " 'across': 810,\n",
              " 'style': 811,\n",
              " 'kardashian': 812,\n",
              " 'employees': 813,\n",
              " 'test': 814,\n",
              " '13': 815,\n",
              " 'cut': 816,\n",
              " 'keeps': 817,\n",
              " 'band': 818,\n",
              " 'industry': 819,\n",
              " 'experience': 820,\n",
              " 'side': 821,\n",
              " 'coffee': 822,\n",
              " 'check': 823,\n",
              " '2014': 824,\n",
              " 'number': 825,\n",
              " 'rubio': 826,\n",
              " 'brings': 827,\n",
              " 'door': 828,\n",
              " 'lead': 829,\n",
              " 'five': 830,\n",
              " 'completely': 831,\n",
              " 'hoping': 832,\n",
              " 'hand': 833,\n",
              " 'university': 834,\n",
              " '2017': 835,\n",
              " 'official': 836,\n",
              " 'starting': 837,\n",
              " 'lose': 838,\n",
              " 'whether': 839,\n",
              " 'force': 840,\n",
              " 'paris': 841,\n",
              " 'weight': 842,\n",
              " 'road': 843,\n",
              " 'space': 844,\n",
              " 'west': 845,\n",
              " 'audience': 846,\n",
              " 'important': 847,\n",
              " 'steve': 848,\n",
              " 'playing': 849,\n",
              " 'reform': 850,\n",
              " 'cool': 851,\n",
              " 'fighting': 852,\n",
              " 'suspect': 853,\n",
              " 'given': 854,\n",
              " 'defense': 855,\n",
              " 'program': 856,\n",
              " 'artist': 857,\n",
              " 'nyc': 858,\n",
              " 'williams': 859,\n",
              " 'role': 860,\n",
              " 'building': 861,\n",
              " 'michelle': 862,\n",
              " 'peace': 863,\n",
              " 'carolina': 864,\n",
              " 'remember': 865,\n",
              " 'chicago': 866,\n",
              " 'act': 867,\n",
              " 'pro': 868,\n",
              " 'possible': 869,\n",
              " 'apartment': 870,\n",
              " 'governor': 871,\n",
              " 'iowa': 872,\n",
              " 'executive': 873,\n",
              " 'success': 874,\n",
              " 'data': 875,\n",
              " 'chance': 876,\n",
              " 'ferguson': 877,\n",
              " 'amazon': 878,\n",
              " 'biggest': 879,\n",
              " 'protesters': 880,\n",
              " 'suicide': 881,\n",
              " 'hall': 882,\n",
              " 'abuse': 883,\n",
              " 'which': 884,\n",
              " 'clearly': 885,\n",
              " 'major': 886,\n",
              " 'push': 887,\n",
              " 'hurricane': 888,\n",
              " 'moore': 889,\n",
              " 'allegations': 890,\n",
              " 'halloween': 891,\n",
              " 'oscars': 892,\n",
              " 'homeless': 893,\n",
              " 'israel': 894,\n",
              " 'general': 895,\n",
              " 'mental': 896,\n",
              " 'coworker': 897,\n",
              " 'moms': 898,\n",
              " 'board': 899,\n",
              " 'close': 900,\n",
              " 'magazine': 901,\n",
              " 'question': 902,\n",
              " 'ben': 903,\n",
              " 'hear': 904,\n",
              " 'demands': 905,\n",
              " 'fear': 906,\n",
              " 'wishes': 907,\n",
              " 'opening': 908,\n",
              " 'members': 909,\n",
              " 'celebrate': 910,\n",
              " 'supporters': 911,\n",
              " 'google': 912,\n",
              " 'football': 913,\n",
              " 'voice': 914,\n",
              " 'easy': 915,\n",
              " 'teens': 916,\n",
              " 'card': 917,\n",
              " 'kerry': 918,\n",
              " 'wait': 919,\n",
              " 'try': 920,\n",
              " 'throws': 921,\n",
              " 'tour': 922,\n",
              " 'pregnant': 923,\n",
              " 'pizza': 924,\n",
              " 'dying': 925,\n",
              " 'press': 926,\n",
              " 'chicken': 927,\n",
              " 'urges': 928,\n",
              " 'reveal': 929,\n",
              " 'simple': 930,\n",
              " 'green': 931,\n",
              " 'economy': 932,\n",
              " 'problems': 933,\n",
              " 'culture': 934,\n",
              " 'lgbtq': 935,\n",
              " 'asking': 936,\n",
              " 'ebola': 937,\n",
              " 'robert': 938,\n",
              " 'learn': 939,\n",
              " 'performance': 940,\n",
              " 'album': 941,\n",
              " 'church': 942,\n",
              " 'begins': 943,\n",
              " 'officer': 944,\n",
              " 'shop': 945,\n",
              " 'poor': 946,\n",
              " 'uses': 947,\n",
              " 'plane': 948,\n",
              " 'families': 949,\n",
              " 'harassment': 950,\n",
              " 'picture': 951,\n",
              " 'jobs': 952,\n",
              " 'fails': 953,\n",
              " 'sean': 954,\n",
              " 'voter': 955,\n",
              " 'beauty': 956,\n",
              " 'demand': 957,\n",
              " 'doctor': 958,\n",
              " \"we're\": 959,\n",
              " 'spot': 960,\n",
              " 'shares': 961,\n",
              " 'leads': 962,\n",
              " 'hilarious': 963,\n",
              " 'suggests': 964,\n",
              " 'rally': 965,\n",
              " 'results': 966,\n",
              " 'ideas': 967,\n",
              " '18': 968,\n",
              " 'jenner': 969,\n",
              " 'arrested': 970,\n",
              " 'male': 971,\n",
              " 'fuck': 972,\n",
              " 'leaving': 973,\n",
              " 'address': 974,\n",
              " 'rest': 975,\n",
              " 'receives': 976,\n",
              " 'amid': 977,\n",
              " 'epa': 978,\n",
              " 'deadly': 979,\n",
              " 'netflix': 980,\n",
              " 'desperate': 981,\n",
              " 'planet': 982,\n",
              " 'cnn': 983,\n",
              " 'marijuana': 984,\n",
              " 'quietly': 985,\n",
              " 'action': 986,\n",
              " 'website': 987,\n",
              " 'pick': 988,\n",
              " 'explains': 989,\n",
              " 'table': 990,\n",
              " 'energy': 991,\n",
              " 'users': 992,\n",
              " 'feeling': 993,\n",
              " 'sales': 994,\n",
              " 'colbert': 995,\n",
              " 'apparently': 996,\n",
              " \"let's\": 997,\n",
              " 'amazing': 998,\n",
              " 'went': 999,\n",
              " 'budget': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9Bf_Fv2TsQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#token.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cBqsBh5UyZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences=token.texts_to_sequences(X)\n",
        "#maxlen=32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cXH74T6O2aQ",
        "colab_type": "code",
        "outputId": "3ee600ae-0b08-433e-c368-f9c0b4d95641",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sequences[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[307, 15114, 678, 3336, 2297, 47, 381, 2575, 15115, 5, 2576, 8433]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUZOZLE0VDto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matrix=pad_sequences(sequences,padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHgShocnOUHo",
        "colab_type": "code",
        "outputId": "5e41bde1-e226-4983-a40c-4488d4cf0185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "np.shape(matrix)\n",
        "print(matrix[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  307 15114   678  3336  2297    47   381  2575 15115     5  2576  8433\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLE30ilKVEAD",
        "colab_type": "code",
        "outputId": "20f14c85-d49c-4769-b260-3bbed2f23401",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.shape(matrix)\n",
        "maxlen=np.shape(matrix)[1]\n",
        "print(maxlen)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vPrjcWFhJgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max=10000\n",
        "tokenizer=Tokenizer(num_words=max)\n",
        "tokenizer.fit_on_texts(x)\n",
        "\n",
        "sequence_matrix=tokenizer.texts_to_matrix(x, mode='tfidf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2bbKzZsGtYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#np.save('sequence_matrix',sequence_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByglowtnHVUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sequence_matrix=None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZVPjBQ3HxEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sequence_matrix=np.load('sequence_matrix.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHnTFuPwiZus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "tokenizer=Tokenizer(num_words=20000)\n",
        "tokenizer.fit_on_texts(x)\n",
        "\n",
        "sequence_matrix1=tokenizer.texts_to_matrix(x, mode='tfidf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWxi1z-yVEPQ",
        "colab_type": "code",
        "outputId": "61de1e64-54bb-45c5-aa27-30b58a4cd0f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab_size=len(token.word_index)+1\n",
        "print(vocab_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29657\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWikSN-1GT_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dense, Dropout, Flatten ,LSTM,CuDNNLSTM\n",
        "from keras.layers import Conv1D,GlobalMaxPool1D,MaxPooling1D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZgzPRM-LLQP",
        "colab_type": "code",
        "outputId": "f018feed-66d5-40f1-9c8a-1f8f3e1c79ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "vocab_size=len(tokenizer.word_index)+1\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-56d5c447fbd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGnRRK75KEqo",
        "colab_type": "code",
        "outputId": "afed8704-afc0-4037-fe8c-a8624d2801f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "\n",
        "embedding_dim = 128\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(vocab_size, embedding_dim))#, input_length=20000))\n",
        "model.add(LSTM(embedding_dim, return_sequences=True))\n",
        "model.add(layers.Conv1D(128, 3, activation='relu'))\n",
        "#model.add(layers.MaxPooling1D(3,strides=2))\n",
        "model.add(layers.GlobalMaxPool1D())\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "#model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.summary()   \n",
        "\n",
        "model.compile(optimizer='Nadam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=(['accuracy']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 128)         3796096   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, None, 128)         131584    \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, None, 128)         49280     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 3,978,261\n",
            "Trainable params: 3,978,261\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xs7IhBvKFaI",
        "colab_type": "code",
        "outputId": "92be9e44-3c57-4a29-8f2f-2c1dd6d1a4b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "\n",
        "model.fit(matrix,Y,batch_size=200,epochs=3,verbose=1,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 21367 samples, validate on 5342 samples\n",
            "Epoch 1/3\n",
            "21367/21367 [==============================] - 10s 447us/step - loss: 0.4599 - acc: 0.7902 - val_loss: 0.3491 - val_acc: 0.8469\n",
            "Epoch 2/3\n",
            "21367/21367 [==============================] - 8s 388us/step - loss: 0.2316 - acc: 0.9242 - val_loss: 0.3771 - val_acc: 0.8446\n",
            "Epoch 3/3\n",
            "21367/21367 [==============================] - 8s 386us/step - loss: 0.1426 - acc: 0.9573 - val_loss: 0.5070 - val_acc: 0.8441\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f37d0234390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJbbMtfVJUsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vVC8Nv1JVCZ",
        "colab_type": "code",
        "outputId": "8a04e866-1730-415a-b1bd-85ce6eaf74f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "source": [
        "model =Sequential()\n",
        "model.add(layers.Embedding(vocab_size,input_length=10000))\n",
        "model.add(layers.GlobalAveragePooling1D())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-8183a5391bed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGlobalAveragePooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'output_dim'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS5-URoiPGKP",
        "colab_type": "code",
        "outputId": "b7963696-5d17-44bc-f00f-81958a94b391",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "model.compile(optimizer='Nadam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z3Nl9_3Oi_S",
        "colab_type": "code",
        "outputId": "65462980-1c9e-4f34-8119-dcfd3ee7ceb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        }
      },
      "source": [
        "model.fit(sequence_matrix,Y,batch_size=200,epochs=5,verbose=1,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "Train on 21367 samples, validate on 5342 samples\n",
            "Epoch 1/5\n",
            "21367/21367 [==============================] - 28s 1ms/step - loss: 0.6867 - acc: 0.5586 - val_loss: 0.6841 - val_acc: 0.5680\n",
            "Epoch 2/5\n",
            "21367/21367 [==============================] - 23s 1ms/step - loss: 0.6864 - acc: 0.5593 - val_loss: 0.6841 - val_acc: 0.5680\n",
            "Epoch 3/5\n",
            "21367/21367 [==============================] - 23s 1ms/step - loss: 0.6864 - acc: 0.5593 - val_loss: 0.6840 - val_acc: 0.5680\n",
            "Epoch 4/5\n",
            "21367/21367 [==============================] - 23s 1ms/step - loss: 0.6864 - acc: 0.5593 - val_loss: 0.6846 - val_acc: 0.5680\n",
            "Epoch 5/5\n",
            " 4400/21367 [=====>........................] - ETA: 17s - loss: 0.6871 - acc: 0.5559"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-d45cace45eee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(sequence_matrix,Y,batch_size=200,epochs=5,verbose=1,\n\u001b[0;32m----> 2\u001b[0;31m           validation_split=0.2)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxaGX0t0Or18",
        "colab_type": "code",
        "outputId": "8ddfdd96-42ff-4a32-e13a-6730fdc6cf4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(layers.Embedding(vocab_size+1, 64,input_length=maxlen))#,mask_zero=True)\n",
        "model.add(layers.Bidirectional(layers.CuDNNLSTM(64,return_sequences=True)))\n",
        "\n",
        "model.add(layers.Bidirectional(layers.CuDNNLSTM(64,return_sequences=False)))\n",
        "#model.add(layers.Conv1D(32, 3, activation='relu'))\n",
        "\n",
        "#model.add(layers.MaxPooling1D(3,strides=2))\n",
        "#model.add(layers.GlobalMaxPool1D())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(rate=0.5))\n",
        "model.add(layers.Dense(64,activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "model.add(layers.Dense(16,activation='relu'))\n",
        "model.add(layers.Dropout(0.4))\n",
        "model.add(layers.Dense(8,activation='relu'))\n",
        "model.add(layers.Dropout(0.3))\n",
        "\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 40, 64)            1898112   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 40, 128)           66560     \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 128)               99328     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 2,092,577\n",
            "Trainable params: 2,092,577\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIp7N4hOhKub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuPtYW-3hTwk",
        "colab_type": "code",
        "outputId": "5d1fd783-d1b6-4775-a8db-42a726d5a513",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        }
      },
      "source": [
        "model.fit(matrix,Y,batch_size=1000,epochs=15,verbose=1,\n",
        "\n",
        "          validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 21367 samples, validate on 5342 samples\n",
            "Epoch 1/15\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "21367/21367 [==============================] - 10s 485us/step - loss: 0.6910 - acc: 0.5363 - val_loss: 0.6865 - val_acc: 0.5680\n",
            "Epoch 2/15\n",
            "21367/21367 [==============================] - 2s 86us/step - loss: 0.6877 - acc: 0.5579 - val_loss: 0.6848 - val_acc: 0.5680\n",
            "Epoch 3/15\n",
            "21367/21367 [==============================] - 2s 86us/step - loss: 0.6867 - acc: 0.5595 - val_loss: 0.6823 - val_acc: 0.5680\n",
            "Epoch 4/15\n",
            "21367/21367 [==============================] - 2s 86us/step - loss: 0.6289 - acc: 0.5449 - val_loss: 0.5110 - val_acc: 0.5680\n",
            "Epoch 5/15\n",
            "21367/21367 [==============================] - 2s 87us/step - loss: 0.5229 - acc: 0.5708 - val_loss: 0.4865 - val_acc: 0.8332\n",
            "Epoch 6/15\n",
            "21367/21367 [==============================] - 2s 87us/step - loss: 0.4504 - acc: 0.8744 - val_loss: 0.5625 - val_acc: 0.8340\n",
            "Epoch 7/15\n",
            "21367/21367 [==============================] - 2s 87us/step - loss: 0.4059 - acc: 0.8961 - val_loss: 0.6667 - val_acc: 0.8300\n",
            "Epoch 8/15\n",
            "21367/21367 [==============================] - 2s 86us/step - loss: 0.3830 - acc: 0.9082 - val_loss: 0.5867 - val_acc: 0.8160\n",
            "Epoch 9/15\n",
            "21367/21367 [==============================] - 2s 86us/step - loss: 0.3592 - acc: 0.9170 - val_loss: 0.7126 - val_acc: 0.8141\n",
            "Epoch 10/15\n",
            "21367/21367 [==============================] - 2s 87us/step - loss: 0.3440 - acc: 0.9247 - val_loss: 0.8681 - val_acc: 0.8222\n",
            "Epoch 11/15\n",
            "21367/21367 [==============================] - 2s 87us/step - loss: 0.3310 - acc: 0.9325 - val_loss: 0.7954 - val_acc: 0.8315\n",
            "Epoch 12/15\n",
            "21367/21367 [==============================] - 2s 86us/step - loss: 0.3193 - acc: 0.9349 - val_loss: 0.9307 - val_acc: 0.8287\n",
            "Epoch 13/15\n",
            "21367/21367 [==============================] - 2s 86us/step - loss: 0.3136 - acc: 0.9366 - val_loss: 0.8184 - val_acc: 0.8173\n",
            "Epoch 14/15\n",
            "21367/21367 [==============================] - 2s 86us/step - loss: 0.3137 - acc: 0.9348 - val_loss: 0.8947 - val_acc: 0.8209\n",
            "Epoch 15/15\n",
            "21367/21367 [==============================] - 2s 86us/step - loss: 0.3052 - acc: 0.9382 - val_loss: 0.9095 - val_acc: 0.8285\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff18c06f8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lB8lhQ8hY_T",
        "colab_type": "code",
        "outputId": "42495bbe-f2f4-485f-fb5a-786040bead33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.shape(matrix)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26709, 40)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E70Md0b4gbSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('model1_85%.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFhp7RUYa_7L",
        "colab_type": "code",
        "outputId": "7b12b505-ccb8-4539-cfd1-f21653b2a7bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size+1, 128))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "#model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(16,activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Dense(8, activation='relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, None, 128)         3796224   \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 3,932,609\n",
            "Trainable params: 3,932,609\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLtA0Vb0gTpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smf8VtdGkCyc",
        "colab_type": "code",
        "outputId": "451aab88-9c8f-4a35-9aa9-2fc2950266c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        }
      },
      "source": [
        "\n",
        "model.fit(matrix,Y,batch_size=1000,epochs=15,verbose=1,\n",
        "\n",
        "          validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 21367 samples, validate on 5342 samples\n",
            "Epoch 1/15\n",
            "21367/21367 [==============================] - 3s 138us/step - loss: 0.0553 - acc: 0.9897 - val_loss: 0.6813 - val_acc: 0.8315\n",
            "Epoch 2/15\n",
            "21367/21367 [==============================] - 3s 131us/step - loss: 0.0528 - acc: 0.9904 - val_loss: 0.6316 - val_acc: 0.8310\n",
            "Epoch 3/15\n",
            "21367/21367 [==============================] - 3s 132us/step - loss: 0.0481 - acc: 0.9914 - val_loss: 0.7861 - val_acc: 0.8317\n",
            "Epoch 4/15\n",
            "21367/21367 [==============================] - 3s 133us/step - loss: 0.0501 - acc: 0.9911 - val_loss: 0.6773 - val_acc: 0.8325\n",
            "Epoch 5/15\n",
            "21367/21367 [==============================] - 3s 132us/step - loss: 0.0468 - acc: 0.9922 - val_loss: 0.6638 - val_acc: 0.8317\n",
            "Epoch 6/15\n",
            "21367/21367 [==============================] - 3s 131us/step - loss: 0.0461 - acc: 0.9926 - val_loss: 0.7091 - val_acc: 0.8304\n",
            "Epoch 7/15\n",
            "21367/21367 [==============================] - 3s 131us/step - loss: 0.0531 - acc: 0.9901 - val_loss: 0.6637 - val_acc: 0.8325\n",
            "Epoch 8/15\n",
            "21367/21367 [==============================] - 3s 132us/step - loss: 0.0478 - acc: 0.9910 - val_loss: 0.7129 - val_acc: 0.8300\n",
            "Epoch 9/15\n",
            "21367/21367 [==============================] - 3s 131us/step - loss: 0.0434 - acc: 0.9923 - val_loss: 0.6544 - val_acc: 0.8300\n",
            "Epoch 10/15\n",
            "21367/21367 [==============================] - 3s 132us/step - loss: 0.0418 - acc: 0.9929 - val_loss: 0.7039 - val_acc: 0.8362\n",
            "Epoch 11/15\n",
            "21367/21367 [==============================] - 3s 132us/step - loss: 0.0487 - acc: 0.9898 - val_loss: 0.5711 - val_acc: 0.8216\n",
            "Epoch 12/15\n",
            "21367/21367 [==============================] - 3s 131us/step - loss: 0.0534 - acc: 0.9881 - val_loss: 0.7432 - val_acc: 0.8310\n",
            "Epoch 13/15\n",
            "21367/21367 [==============================] - 3s 131us/step - loss: 0.0435 - acc: 0.9918 - val_loss: 0.6675 - val_acc: 0.8330\n",
            "Epoch 14/15\n",
            "21367/21367 [==============================] - 3s 131us/step - loss: 0.0475 - acc: 0.9904 - val_loss: 0.6561 - val_acc: 0.8235\n",
            "Epoch 15/15\n",
            "21367/21367 [==============================] - 3s 131us/step - loss: 0.0584 - acc: 0.9860 - val_loss: 0.8086 - val_acc: 0.8310\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc6ce916da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0eviqGikHss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYSy0EfTBe74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}